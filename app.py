__import__('pysqlite3')
import sys
sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')
import streamlit as st
from agentic_rag import initialize_app
import sys
import io
import os
import time


# Configure the Streamlit page layout
st.set_page_config(
    page_title="Smart Business Guide",
    layout="wide",
    initial_sidebar_state="expanded",
    page_icon = "üß†"
)


# Initialize session state for messages
if "messages" not in st.session_state:
    st.session_state.messages = []

# Sidebar layout
with st.sidebar:
    try:
        st.image("LOGO_UPBEAT.jpg", width=150, use_container_width=True)
    except Exception as e:
        st.warning("Unable to load image. Continuing without it.")

    st.title("üó£Ô∏è Smart Guide 1.0")
    st.markdown("**‚ñ∂Ô∏è Actions:**")

    # Initialize session state for the model if it doesn't exist
    if "selected_model" not in st.session_state:
        st.session_state.selected_model = "llama-3.1-8b-instant"

    model_list = [
        "llama-3.1-8b-instant",
        "llama-3.3-70b-versatile",
        "llama3-70b-8192",   
        "llama3-8b-8192", 
        "mixtral-8x7b-32768", 
        "gemma2-9b-it",
        "gpt-4o-mini",
        "gpt-4o"
    ]

    with st.expander("‚öôÔ∏è Settings", expanded=False):
        st.session_state.selected_model = st.selectbox(
            "üß† Select Model",
            model_list,
            key="model_selector",
            index=model_list.index(st.session_state.selected_model)
        )
        # Add the slider for answer style
        answer_style = st.select_slider(
            "üí¨ Answer Style",
            options=["Concise", "Moderate", "Explanatory"],
            value="Concise",
            key="answer_style_slider",
            disabled=False
        )

    search_option = st.radio(
        "Search options",
        ["Smart guide + tools", "Internet search only", "Hybrid search (Guides + internet)"],
        index=0
    )

    # Set the corresponding boolean values based on the selected option
    hybrid_search = search_option == "Hybrid search (Guides + internet)"
    internet_search = search_option == "Internet search only"
    
    reset_button = st.button("üîÑ Reset Conversation", key="reset_button")


    # Initialize the app with the selected model
    app = initialize_app(st.session_state.selected_model, hybrid_search, internet_search, answer_style)
    if reset_button:
        st.session_state.messages = []
# Title
st.title("üìò Smart Guide for Entrepreneurship and Business Planning in Finland")
st.markdown(
    """
    <div style="text-align: left; font-size: 18px; margin-top: 20px; line-height: 1.6;">
        ü§ñ <b>Welcome to your Smart Business Guide!</b><br>
        I am here to assist you with:<br>
        <ul style="list-style-position: inside; text-align: left; display: inline-block;">
            <li>AI agents based approach for finding answers from business and entrepreneurship guides in Finland</li>
            <li>Providing up-to-date information through AI-based internet search</li>
            <li>Automatically invoking AI-based internet search based on query understanding </li>
            <li>Specialized tools for tax-related information, permits & licenses, business registration, residence permits, etc. :</li>
        </ul>
        <p style="margin-top: 10px;"><b>Start by typing your question in the chat below, and I'll provide tailored answers for your business needs!</b></p>
    </div>
    """,
    unsafe_allow_html=True
)

# Display conversation history
for message in st.session_state.messages:
    if message["role"] == "user":
        with st.chat_message("user"):
            st.markdown(f"**You:** {message['content']}")
    elif message["role"] == "assistant":
        with st.chat_message("assistant"):
            st.markdown(f"**Assistant:** {message['content']}")

# Input box at the bottom for new messages
if user_input := st.chat_input("Type your question (Max. 100 char):"):
    if len(user_input) > 100:
        st.error("Your question exceeds 100 characters. Please shorten it and try again.")
    else:
        # Add user's message to session state and display it
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.markdown(f"**You:** {user_input}")

        # Capture print statements from agentic_rag.py
        output_buffer = io.StringIO()
        sys.stdout = output_buffer  # Redirect stdout to the buffer

        try:
            with st.chat_message("assistant"):
                response_placeholder = st.empty()
                debug_placeholder = st.empty()
                streamed_response = ""

                # Show spinner while streaming the response
                with st.spinner("Thinking..."):
                    #inputs = {"question": user_input}
                    inputs = {"question": user_input, "hybrid_search": hybrid_search, "internet_search":internet_search, "answer_style":answer_style}
                    for i, output in enumerate(app.stream(inputs)):
                        # Capture intermediate print messages
                        debug_logs = output_buffer.getvalue()
                        debug_placeholder.text_area(
                            "Debug Logs",
                            debug_logs,
                            height=100,
                            key=f"debug_logs_{i}"
                        )

                        if "generate" in output and "generation" in output["generate"]:
                            # Append new content to streamed response
                            streamed_response += output["generate"]["generation"]
                            # Update the placeholder with the streamed response so far
                            response_placeholder.markdown(f"**Assistant:** {streamed_response}")

                # Store the final response in session state
                st.session_state.messages.append({"role": "assistant", "content": streamed_response or "No response generated."})
        except Exception as e:
            # Handle errors and display in the conversation history
            error_message = f"An error occurred: {e}"
            st.session_state.messages.append({"role": "assistant", "content": error_message})
            with st.chat_message("assistant"):
                st.error(error_message)
        finally:
            # Restore stdout to its original state
            sys.stdout = sys.__stdout__
